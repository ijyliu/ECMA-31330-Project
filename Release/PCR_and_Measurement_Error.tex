\documentclass[12pt]{article}
\usepackage{booktabs}
\usepackage{graphicx}
%\usepackage{subcaption}
\usepackage{caption}
\usepackage{mathtools}
\usepackage{tikz,pgfplots}
\usepackage{subfig}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[shortlabels]{enumitem}
\usetikzlibrary{angles,patterns,calc}
\usepackage{bbm}
\usepackage{float}
\newcommand\der[2]{\frac{\partial{#1}}{\partial{#2}}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

% stuff to put matlab code in 
\usepackage{listings}
\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}

% Shortcut greek
\def\a{\alpha}
\def\b{\beta}
\def\g{\gamma}
\def\D{\Delta}
\def\d{\delta}
\def\z{\zeta}
\def\k{\kappa}
\def\l{\lambda}
\def\n{\nu}
\def\r{\rho}
\def\s{\sigma}
\def\t{\tau}
\def\x{\xi}
\def\w{\omega}
\def\W{\Omega}

\usepackage[autostyle, english = american]{csquotes}
\MakeOuterQuote{"}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{fancyhdr}
\fancypagestyle{firststyle}
{
\fancyhf{}
    \renewcommand{\headrulewidth}{0pt}
   \fancyfoot[C]{\footnotesize Page \thepage\ of \pageref{LastPage}}
}

\newcommand{\numpy}{{\tt numpy}}    % tt font for numpy

\topmargin -.5in
\textheight 9in
\oddsidemargin -.25in
\evensidemargin -.25in
\textwidth 7in

\newcommand{\question}[1]{ \begin{center} \noindent\colorbox{gray!10}{
\parbox{0.8\textwidth}{\vspace{0.125in} #1 \vspace{0.125in} } } \end{center} }

\begin{document}

    \thispagestyle{firststyle}

    \author{Isaac Liu, Nicol\'as Martorell \& Paul Opheim}
    \title{Attenuation Bias, Measurement Error \& Principal Component Analysis} 
    \maketitle

    % code

    \lstset{language=Matlab,%
        %basicstyle=\color{red},
        breaklines=true,%
        morekeywords={matlab2tikz},
        keywordstyle=\color{blue},%
        morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},
        identifierstyle=\color{black},%
        stringstyle=\color{mylilas},
        commentstyle=\color{mygreen},%
        showstringspaces=false,%without this there will be a symbol in the places where there is a space
        numbers=left,%
        numberstyle={\tiny \color{black}},% size of the numbers
        numbersep=9pt, % this defines how far the numbers are from the text
        emph=[1]{for,end,break},emphstyle=[1]\color{red}, %some words to emphasise
        %emph=[2]{word1,word2}, emphstyle=[2]{style},    
    }

    \begin{abstract}

        Shorter version of the abstract (I would say 4-5 sentences in a single paragraph max) goes here
        
    \end{abstract}

    \newpage \clearpage

    % Introduction (no need for a section header for this)

        Many variables of interest in economics are not directly available as empirical data. Instead, economists often use other variables that are imperfect measurements of the true focus of their analysis. These available variables are known as \textit{proxies} or ``variables measured with error'', and, if they suffer from classical measurement error, their use causes \textit{attenuation bias} when they are used as independent variables in econometric estimation. Traditionally, instrumental variables are used as a shock of exogeneity to get rid of this bias, but finding truly exogenous variables that satisfy the exclusion restriction is difficult, and so this method can often not be feasibly applied.

        As an alternative to dealing with attenuation bias, we propose the use of Principal Component Analysis (PCA) over several variables measured with error. When there are multiple observed variables driven by a single ``true'' one, we propose to use PCA over these variables to extract the ``true'' variable. We then use this extracted value and use it in a standard OLS regression, thus providing a solution to attenuation bias that does not require the strong assumptions of instrumental variable analysis.

        To show the properties and behaviour of our estimator on large samples under standard assumptions, we present a theoretical framework and a Monte-Carlo analysis. Additionally, we explore a basic empirical application to our method, by estimating the effect of economic development on life expectancy at birth. Since there is no consensus on how to measure economic development, we take a sample of different variables that may measure economic development with error (GDP per capita, GNI per capita, Household Income Per Capita, among others) over which we apply PCA to apply our identification strategy.

        Summarize Findings

    \section*{Literature}

        Somewhat similarly to our methods, (Nagasawa 2020) develops the use of a proxy variable to deal with unobserved heterogeneity in nuisance parameters and uses a partial effects method. Differing from our setting, (Schennach 2016) focuses on nonclassical measurement error and nonlinear cases and notes the usefulness of factor methods and some cases where they are of more use than instrumental variables. (Wegge) considers a setting in which measurement error regression models are factor analysis models, with the correct regressors being the factors. Latent factors are uncorrelated with the errors. Focusing on measurment error in the main regressor, (Schoefield) combines solutions from strucutral equations modelling and iterm response theory to deal with misestimation. Finally, (Heckman 2010) considers a situation similar to ours, except involving matching estimators. In this case, these estimators can be harmed by mismeasured conditioning variables. However, average treatment effects can be identified using factor proxies, and without need for normalization.

    \section*{Theoretical framework}

        Consider a model where the outcome is denoted by $y_i$. This outcome depends on a variable of interest denoted by $t_i$ and a vector of covariates denoted by $X_i=(x_{i,1},x_{i,2},\dots x_{i,p})'$. Additionally, consider a vector of variables $X^*_i=(x^*_{i,1},x^*_{i,2},\dots x^*_{i,p})'$ that correspond to the covariates $X_i$ but observed with measurement error, where $x^*_{i,k}=x_{i,k}+\eta_{i,k}$ with $\eta_{i,k} \sim {iid}(0,\sigma^2_{\eta_k})$, $\operatorname{E}(x_{i,k}'\eta_{i,k})=0, \forall i$, $\operatorname{E}(x_{i,k}'\eta_{j,l})=0, \forall i\neq j$ and $k \neq l$, and $\operatorname{E}(\eta_{i,k}'\eta_{j,l})=0, \forall i\neq j$ and $k \neq l$. Therefore, each $x^*_{i,k}$ suffers from classical measurement error. Note that $\operatorname{E}(x_{i,k})=\operatorname{E}(x^*_{i,k})=\mu_{x_k}$ and that $\operatorname{V}(x_{i,k})=\sigma^2_{x_k}$ while $\operatorname{V}(x^*_{i,k})=\sigma^2_{x_k}+\sigma^2_{\eta_k}\geq \sigma^2_{x_k}$.

    \subsection*{Data Generating Process}

        Assume that the outcome $y_i$ is determined by the following Data Generation Process (DGP):
        \begin{align}
            y_i = \gamma t_i + X_i'\beta + \epsilon_i
        \end{align}

        where $\g$ is the parameter of the variable of interest $t_i$, $\b=(\b_1,\b_2,\dots \b_p)'$ is the vector of the parameters of the covariates $X_i$ including a constant and $\epsilon_i \sim \operatorname{iid}(0,\sigma^2_\epsilon)$. Under this specification, the coefficients are such that:
        \begin{align}
            \left(\begin{array}{l}
        {\gamma} \\
        {\beta}
        \end{array}\right)=\left(\begin{array}{cc}
        {\sigma}^2_{t} & \Sigma_{tX} \\
        \Sigma_{Xt} & {\Sigma}_{X}
        \end{array}\right)^{-1}\left(\begin{array}{c}
        \Sigma_{yt} \\
        \Sigma_{yX}
        \end{array}\right)
        \end{align}

        Suppose that the econometrician has access to $t_i$ but, instead of $X_i$ she observes $X^*_i$. Then, she specifies the following linear model
        \begin{align}
            y_i = \gamma^* t_i + {X^{*}_i}' \beta^* + \zeta_i
        \end{align}

        the coefficients would be such that
        \begin{align}
            \left(\begin{array}{l}
        {\gamma}^* \\
        {\beta}^*
        \end{array}\right)&=\left(\begin{array}{cc}
        {\sigma}^2_{t} & \Sigma_{tX^*} \\
        \Sigma_{X^*t} & {\Sigma}_{X^*}
        \end{array}\right)^{-1}\left(\begin{array}{c}
        \Sigma_{yt} \\
        \Sigma_{yX^*}
        \end{array}\right) \\
        & =\left(\begin{array}{cc}
        {\sigma}^2_{t} & \Sigma_{tX} \\
        \Sigma_{Xt} & {\Sigma}_{X}+{\Sigma}_{\eta}
        \end{array}\right)^{-1}\left(\begin{array}{cc}
        {\sigma}^2_{t} & \Sigma_{tX} \\
        \Sigma_{Xt} & {\Sigma}_{X}
        \end{array}\right)\left(\begin{array}{l}
        {\gamma} \\
        {\beta}
        \end{array}\right)
        \end{align}

        To the see the implications of the of this measurement error in the covariates, consider a simple case where the DGP depends only of the variable of interest and a covariate such that:

        \begin{align}
            \left(\begin{array}{l}
        {\gamma} \\
        {\beta}
        \end{array}\right)=\left(\begin{array}{l}
        1 \\
        1
        \end{array}\right)
        \end{align}

        and with $\sigma^2_t=\Sigma_X=\Sigma_\eta=1$ while $\Sigma_{Xt}=0.6$. Then
        \begin{align*}
            \left(\begin{array}{l}
        {\gamma}^* \\
        {\beta}^*
        \end{array}\right)& =\left(\begin{array}{cc}
        1 & 0.6 \\
        0.6 & 2
        \end{array}\right)^{-1}\left(\begin{array}{cc}
        1 & 0.6 \\
        0.6 & 1
        \end{array}\right)\left(\begin{array}{l}
        1\\
        1
        \end{array}\right) \\
        \left(\begin{array}{l}
        {\gamma}^* \\
        {\beta}^*
        \end{array}\right)&=\left(\begin{array}{l}
        1.37 \\
        0.39
        \end{array}\right)
        \end{align*}

        Clearly, both coefficients shows bias when the econometrician assumes a DGP with $X_i^*$: while there is attenuation bias on the coefficient of the covariate, the coefficient of the variable of interest is biased upward given that some of the effect of the covariates is ``omitted'' given this attenuation.

    \subsection*{Instrumental Variables Regression as a Bias-Correction Method}

        The classical solution for the measurement-error induced bias in econometrics has been the usage of instrumental variables. Suppose an instrument $Z_i$ that satisfies the relevance condition $\operatorname{E}(Z_i'X_i)\neq 0$ and $\operatorname{E}(Z_i't_i)\neq 0$, and also the exclusion restriction $\operatorname{E}(Z_i'\epsilon_i)=\operatorname{E}(Z_i'\zeta_i)=\operatorname{E}(Z_i'\eta_{i,k})=0$, for all $i$ and $k$. Then premultiplying by $Z_i$ we have
        \begin{align}
            Z_i'y_i =  Z_i'\gamma^* t_i +  Z_i'{X^{*}_i}' \beta^* +  Z_i'\zeta_i
        \end{align}

        and so
        \begin{align}
            \left(\begin{array}{l}
        {\gamma}^{IV} \\
        {\beta}^{IV}
        \end{array}\right)
        & =\left(\begin{array}{cc}
        {\Sigma}_{Zt} & \Sigma_{ZX,Zt} \\
        \Sigma_{Zt,ZX}& {\Sigma}_{ZX}+{\Sigma}_{Z\eta}
        \end{array}\right)^{-1}\left(\begin{array}{cc}
        {\Sigma}_{Zt} & \Sigma_{ZX,Zt} \\
        \Sigma_{Zt,ZX} & {\Sigma}_{ZX}
        \end{array}\right)\left(\begin{array}{l}
        {\gamma} \\
        {\beta}
        \end{array}\right)\\
        & =\left(\begin{array}{cc}
        {\Sigma}_{Zt} & \Sigma_{ZX,Zt} \\
        \Sigma_{Zt,ZX}& {\Sigma}_{ZX}
        \end{array}\right)^{-1}\left(\begin{array}{cc}
        {\Sigma}_{Zt} & \Sigma_{ZX,Zt} \\
        \Sigma_{Zt,ZX} & {\Sigma}_{ZX}
        \end{array}\right)\left(\begin{array}{l}
        {\gamma} \\
        {\beta}
        \end{array}\right) \\
        \left(\begin{array}{l}
        {\gamma}^{IV} \\
        {\beta}^{IV}
        \end{array}\right)
        & =\left(\begin{array}{l}
        {\gamma} \\
        {\beta}
        \end{array}\right)
        \end{align}

        However, finding a reliable source of exogeneity is difficult, and it is impossible to conclusively prove a suitable exclusion restriction. The use of IV as a bias-correction method is thus often unfeasible.\\

    \subsection*{Principal Component Regression as Bias-Correction Method}

        Alternatively, we propose an alternative bias-correction method for when there are several mismeasured variables for each covariate; that is, when we have more than one $x_{i,k}^*$ for every $x_{i,k}$. Given that in all the mismeasured variables the underlying value is the real value, one could think of extracting the underlying true $x_{i,k}$ through a linear combination of the different $x_{i,k}^*$. Then, we could treat all the $x_{i,k}^*$ as variables that share components as follows:
        \begin{align}
        h_{j}=\underset{h^{\prime} h=1, h^{\prime} h_{1}=0, \ldots, h^{\prime} h_{j-1}=0}{\operatorname{argmax}} \operatorname{var}\left[h^{\prime} X^*_k\right]  
        \end{align}


        where $h_j$ is the eigenvector of $\Sigma$ associated with the $j^{t h}$ ordered eigenvalue $\lambda_{j}$ of $\Sigma_{X^*_k}$, and the principal components of $X^*_k$ are $U_{j}=h_{j}^{\prime} X^*_k$, where $h_{j}$ is the eigenvector of $\Sigma$ associated with the $j^{t h}$ ordered eigenvalue $\lambda_{j}$ of $\Sigma$.\\

        Under our assumptions, the vector of mismeasured values $X^*_k$ of $x_{i,k}$, share only one principal component which is precisely $x_{i,k}$. Then, we only have one principal component, $x_{i,k}$, and so the $x_{i,k}$ is such that
        \begin{align}
            x_{i,k}=h_{k}^{\prime} X^*_k
        \end{align}

        Finally, we could then retrieve the vector of true variables $X_i$
        \begin{align}
            X_i=HX^*_i
        \end{align}

        where $H$ is a matrix such that
        \begin{align*}
            H=\left(\begin{array}{ccccc}
            h_1 & 0 & 0 & \dots & 0 \\
            0 & h_2 & 0 & \dots & 0 \\
            \vdots & \ddots & h_3 & \ddots & \vdots \\
            0 & \dots & \dots & \dots \ddots & h_p
            \end{array}\right)
        \end{align*}

        and $h_k$ is the vector of eigenvalues for the variable $x_{i,k}$.

        Our new linear model then becomes
        \begin{align}
            y_i = \gamma^{PCR} t_i + H{X^*_i}'\beta^{PCR} + \epsilon_i
        \end{align}

        where the coefficients are as follows
        \begin{align}
            \left(\begin{array}{l}
            {\gamma}^{PCR} \\
            {\beta}^{PCR}
            \end{array}\right)&=\left(\begin{array}{cc}
            {\sigma}^2_{t} & \Sigma_{t,HX^*} \\
            \Sigma_{HX^*,t} & {\Sigma}_{HX^*}
            \end{array}\right)^{-1}\left(\begin{array}{c}
            \Sigma_{yt} \\
            \Sigma_{y,HX^*}
            \end{array}\right)\\
            &=\left(\begin{array}{cc}
            {\sigma}^2_{t} & \Sigma_{t,HX^*} \\
            \Sigma_{HX^*,t} & {\Sigma}_{HX^*}
            \end{array}\right)^{-1}\left(\begin{array}{cc}
            {\sigma}^2_{t} & \Sigma_{tX} \\
            \Sigma_{Xt} & {\Sigma}_{X}
            \end{array}\right)\left(\begin{array}{l}
            {\gamma} \\
            {\beta}
            \end{array}\right)\\
            &=\left(\begin{array}{l}
            {\gamma} \\
            {\beta}
            \end{array}\right)
        \end{align}

        where the last equality comes from $(13)$.

    \section*{Properties of the Estimator: Monte Carlo Simulations}

        We then complement our theoretical analysis by using Monte Carlo Simulation to analyze the effects of using Principal Components Regression as a method of bias correction. For these simulations, we assume that the true DGP for the data is:

        $$y_i = \beta_1 x_i + \beta_2 z_i + u_i$$

        where $x_i$ and $z_i$ are single variables drawn from $\mathcal{N}(\begin{bmatrix} 0\\ 0 \end{bmatrix}, \begin{bmatrix} 1 & \rho\\ \rho & 1\end{bmatrix})$, where $\rho$ is some covariance between our main variable of interest ($x_i$) and the covariate ($z_i$). The $u_i$ is drawn from a white noise distribution($\mathcal{N}(0,1)$) that is uncorrelated with both $x_i$ and $z_i$. We then assume (as with the theoretical analysis) that $z_i$ is not directly observable and instead the researchers only have access to $p$ many measurements $z_{i,j}^*$ where $z_{i,j}^* = z_i + \eta_j$ where $\eta_j$ is drawn from a white noise distribution $\mathcal{N}(\mathbf{0},\Sigma)$ where $\mathbf{0}$ is a p-vector and $\Sigma$ is a diagonal p by p matrix with only 1s on the diagonal.\\
        
        In our simulations, we assume default values of $\rho = 0.5$, $\beta_1 = \beta_2 = 1$, and $p=5$. We then vary each factor while holding the others fixed, and perform 1,000 simulations of the DGP followed by an OLS regression on either the PCA value from the p measurements of the true $z_i$, or on a single one of the measurements of $z_i$. For each simulation, we generate 100 observations of $y_i,x_i$,etc. Table \ref{sim_p_2} shows the results for different values of $p$.

        \clearpage

        \input{../Output/Tables/sim_reg_results_p_2methods.tex}

        We can see that using PCA to extract the latent covariate driving the mismeasured covariates noticeably outperforms using a single mismeasured covariate across several values of $p$. Both the average coefficient on $\beta_1$ obtained when including the PCA output in the regression, and the mean absolute percentage error obtained on the 1,000 simulations are both much closer to the target values with the PCA-based regression than with the single measurement regression. Additionally, we can see that as $p$ increases the estimated $\beta_1^*$ coefficient in the PCA regression gets steadily closer to the true $\beta_1$ value of 1. This trend could well continue as $p \to \infty$, but we did not simulate values greater than $p = 50$ due to the seeming implausibility of having more than 50 measurements of the same single covariate. Appendix 1 contains charts that show that this increase in performance is also true for different values of $\beta_1$ and $\beta_2$.\\

        % NOTE: would be nice to reference the tables discussed with \ref
        However, there are certain circumstances where the PCA method does not lead to more accurate estimates of $\beta_1^*$. Table \ref{sim_rho_2} contains the simulation results for different values of $\rho$ (the covariance between the main variable of interest $x_i$ and the true latent covariate $z_i$).

        \clearpage

        \input{../Output/Tables/sim_reg_results_rho_2methods.tex}

        We first note that when $\rho = 0.5$ then the coefficient on the variable of interest is artificially inflated when we use a single mismeasurement as a covariate (on average, 1.28 instead of the true value of 1). Similarly, when $\rho = -0.5$ then the coefficient is artificially deflated. Using the PCA value as the covariate reduces this bias for both directions, and brings the main coefficient closer to its true value of zero. These results are consistent with our theoretical section, where we argued that a positive covariance between the main variable and the true covariate will lead to an inflation on the main coefficient, while a negative covariance will lead to a deflation of the coefficient. Separately, when the covariance between $x_i$ and $z_i$ is equal to $0, -1$, or $1$ then there is no notable improvement from using the PCA-extracted latent variable (and notice that since the variances of $x_i$ and $z_i$ are 1, this means that the covariance is equal to the correlation in these simulations). These simulation results suggest that so long as the correlation between $x_i$ and $z_i$ is not close to $-1$,$0$, or $1$, there are noticeable performance gains from using PCA to extract the true covariate from a collection of observed variables that try to measure that true covariate.\\
        
        However, the performance advantages that we see from using PCA could be driven by the benefit of having multiple measurements of our true covariate of interest, as opposed to any special advantages from PCA specifically. We test this question by comparing the estimated $\beta_1^*$ in our PCA regressions with the estimated $\beta_1^*$ when we include all $p$ measurements as separate covariates in the regression, and the $\beta_1^*$ obtained when the covariate is the mean of all $p$ measurements of the true covariate. The results from these regressions for different values of $p$ are shown in Table \ref{sim_p_3}.

        \clearpage

        \input{../Output/Tables/sim_reg_results_p_3methods.tex}

        As one can see from these results (and results for different values of $\beta_1$, $\beta_2$, and $\rho$ in Appendix 2), there does not seem to be a noticeable difference between these three regression methods (across any values of $p, \beta_1,\beta_2$, and $\rho$. Thus, our simulations suggest that there are major benefits to having multiple measurements of a latent covariate of interest, but that using PCA, taking the average of these measurements, and including all measurements as separate covariates seem to give similar benefits to the performance of the regression.


    \section*{Application: Government Share of Healthcare Spending and Life Expectancy}

        We now examine the implications of the principal components estimator in an empirical setting with measurement error. One interesting question in public economics and public health is the comparison between publicly and privately funded healthcare systems and outcomes such as life expectancy. To measure the public or private nature of a healthcare system we use the continuous variable of the government's share of total health expenditure in a given country and year.

        Some previous work has covered this relationship. Considerig that this topic has been studied in "relatively few papers," (Linden and Ray) focus on the relationship between life expectancy at birth and public and private health expenditures for 34 OECD countries from 1970-2012 and find that both public and private health spending are important to life expectancy and are associatied with each other. Other studies find a variety of effects; considering developing nations in Africa, (Novignon) finds a larger impact for public spending while (Fillmer) finds no impact; in the developed US and Canada, (Lichtenberg) finds an impact only for public spending on outcomes when controlling for lagged GDP, while (Cremieux) finds private spending on drugs is more effective. In the most similar work to ours, (Or 2000) predicts premature death in 21 OECD countries from 1970-1992, considering the public share of health expenditure, environmental factors, and GDP. He finds that a larger share of public spending is associated with lower rates of premature mortality for both males and females, and that controlling for GDP is important; it is also associated with less premature mortality. This work also demonstrates the importance of our methods of reducing the number of covariates considered, as it includes many economic variables and fixed effects but examines only several hundred observations; the estimators used may be subject to an important amount of variance.

        In this regression it is important to account for the role of a country's level of economic development. There is an extensive literature documenting the relationship between economic development and life expectancy. (Ling et al) finds that economic growth is associated with increased life expectancy in Malaysia, while considering the reversed causal direction (Acemoglu) finds improvements in life expectancy lead to little or no growth. Somewhat less obvious is the linkage between government provision of healthcare and development. In general, public goods provision and government spending, including in fields such as healthcare has been linked to prosperity; low income countries may be remain in such a state due to inefficient govenrments and inferior institutions (Wu).

        However, economic development as it is often conceptualized using GDP is liable to be measured with error. GDP measurements usually rely on company surveys, and the methodology within a country and for comparisons between countries through exchange rates or PPP adjustments may vary (Grishin). Other sources of error include the presence of the informal economy and non-monetary but productive work, and the challenge of accurately measuring the value of digital services which often do not have visible prices (Charmes, Ahmad).\footnote{Due to differences in statistical capacity and the larger relative size of the informal economy, it is possible that mismeasurement of economic development is particularly severe in developing countries. On the other hand, the presence of the digital economy may mean mismeasurement is larger in developed nations. This would constitute the presence of non-classical measurement error, but we only consider classical measurement error in this paper.} Hence, this setup, with a covariate in regression subject to measurement error, fits the situation described in the theory and simulations in the previous sections. In this case, we aim to to reduce possible bias in the coefficient of the government's share of health spending by making appropriate use of multiple measures of economic development.

        % Go into more detail on what particular simulation parameters we envision

        Our data on all measures comes from the World Bank, though we also make usage of OECD government health share data to fill in missing years, and average World Bank and OECD measurements when both are available (World Bank, OECD). We standardize all variables by subtracting the mean and dividing by the standard deviation, linearly interpolate data between known observations, and remove country-years with missing values for any of the economic indicators.

        % need to compile stats in terms of what country years are missing in WB versus OECD
        % does the averaging do anything? seems kind of sketchy because it's like measurement error in the variable of interest as well!

        % Add \ref to the following table?
        In Table \ref{main_regs} below we begin with a univariate OLS regression, which produces a large and significant coeffcient indicating a one standard deviation increase in the government share of health expenditure is linked to a 0.56 standard deviation increase in life expectancy. Next we include the potentially mismeasured covariate of GDP per capita, which greatly reduces the size of the coefficient on the governments share. After this we include a full set of economic covariates listed in Table \ref{Econ_Indicators}, again reducing the size of the coefficient. However, this result is then adjusted upwards again in the last two columns, where use the mean of the mismeasured covariates, and the first principal component.

        \input{../Output/Tables/LE_Health_Econ_Regressions_combined.tex}

        \begin{table}[!htbp] \centering
            \caption{Econ Indicators \label{Econ_Indicators}}
            \input{../Output/Tables/indicators.tex}
        \end{table}

        The results clearly demonstrate that all of the methods using multiple measures of the covariates produce noticably different coefficients for government health share. Taking the mean of covariates produces a larger coefficient. The principal components estimator and the usage of many economic indicators directly instead produce smaller coefficients.

        Moreover, these different coefficients behave in a manner similar to that predicted by our theoretical development and simulations. In Table \ref{sim_rho_2}, we saw the impact of variation in $\rho$, the correlation between measurements for a value of $p = 5$ and $\beta = 1$ for 100 observations. In the empirical setting it is difficult to tell what is a reasonable value of $\beta$, and we instead have nearly 2000 observations. Nevertheless, we see that for a positive $\rho$ value between 0 and 1 (as is likely to be the case in light the correlation between GDP and the government share of health spending and overall public goods), the coefficient obtained from using a single measurement is inflated relative to that from PCA, and presumably other methods combining multiple measures as in columns (3), (4), and (5) of Table \ref{Econ_Indicators}.

        Results using fixed effects panel models, more principal components, and instrumental variables regression of using all the economic indicators as an instrument for GDP per capita, are in Table \ref{additional_regs}. Fixed effects coefficients greatly reduce the magnitude of effects. Including more principal components and the instrumental variables technique produce coefficients of moderate size close to that obtained by the single principal component. The results in column (3) and (4) also show reductions in the inflation of coefficients relative to column (2) of Table \ref{Econ_Indicators}.

        \input{../Output/Tables/Additional_LE_Health_Econ_Regressions_combined.tex}

    \section*{Conclusion}
        
        Discuss possible extensions

    \clearpage \newpage

    \appendix

    \section*{Appendix 1}

        \input{../Output/Tables/sim_reg_results_beta1_2methods.tex}
        \input{../Output/Tables/sim_reg_results_beta2_2methods.tex}
        %\input{../Output/Tables/sim_reg_results_p_2methods.tex}
        %\input{../Output/Tables/sim_reg_results_rho_2methods.tex}
        
    \section*{Appendix 2}


        \input{../Output/Tables/sim_reg_results_beta1_3methods.tex}
        \input{../Output/Tables/sim_reg_results_beta2_3methods.tex}
        %\input{../Output/Tables/sim_reg_results_p_3methods.tex}
        \input{../Output/Tables/sim_reg_results_rho_3methods.tex}


    \section*{Appendix 3}

        \begin{figure}[h!]
            \centering
            \caption{Correlations Between Covariates and Life Expectancy}
            \label{LE_Health_Econ_Correlations}	
            \includegraphics[width=\linewidth,keepaspectratio=true]{../Output/Figures/LE_Health_Econ_Correlations_combined.pdf}
        \end{figure}

        \begin{figure}[h!]
            \centering
            \caption{Economic Measures PCA Loadings}
            \label{Econ_Loadings}	
            \includegraphics[width=\linewidth,keepaspectratio=true]{../Output/Figures/Econ_Indicator_Loadings_combined.pdf}
        \end{figure}

        \begin{figure}[h!]
            \centering
            \caption{Economic Measures PCA Share of Variance Explained}
            \label{Econ_Share_Explained}	
            \includegraphics[width=\linewidth,keepaspectratio=true]{../Output/Figures/Econ_Indicator_Share_Explained_combined.pdf}
        \end{figure}

\end{document}